\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Computer Modern (default LaTeX font) - no package needed
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{caption}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\title{The Advice Gap: Gender Disparities in Online Relationship Advice Communities}

\author{
    Henry Stanley\\
    \texttt{henry@henrystanley.com}
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Online advice communities provide a valuable resource for individuals seeking guidance on personal matters, yet little is known about whether the advice received varies systematically by the advice-seeker's demographic characteristics. We analyze 6,080 advice comments from 591 relationship advice posts on Ask Metafilter, using large language model (LLM) classification to measure advice direction (supportive vs.\ critical). We find substantial gender disparities: men receive critical advice at 4.19 times the rate of women (27.4\% vs.\ 8.3\%, $\chi^2 = 381.80$, $p < 0.0001$). These differences persist after controlling for situation severity, poster fault, and problem category. Validation against human judgment shows 96\% agreement on advice direction classification. Our findings suggest that gender shapes the advice-giving dynamic in online communities, with potential implications for help-seeking behavior and platform design.

\vspace{0.5em}
\noindent\textbf{Keywords:} gender bias, online communities, advice-seeking, content analysis, LLM classification
\end{abstract}

\section{Introduction}

Online advice communities have become a significant resource for individuals navigating personal challenges. Platforms like Reddit's r/relationships, Ask Metafilter, and various Facebook groups provide spaces where people can anonymously describe interpersonal problems and receive feedback from community members. This crowdsourced advice model offers accessibility and diverse perspectives, but also raises questions about the quality and consistency of the guidance provided.

Prior research has documented gender differences in various online contexts, including Wikipedia editing \citep{lam2011wp}, Stack Overflow participation \citep{ford2016paradise}, and social media harassment \citep{duggan2017}. However, less attention has been paid to whether the \emph{content} of interactions---specifically, the advice given to help-seekers---varies by the help-seeker's gender.

This study examines whether men and women receive systematically different advice when posting about relationship problems in an online community. We focus on advice direction---whether commenters support or criticize the original poster (OP).

Our research questions are:

\begin{itemize}
    \item \textbf{RQ1}: Do men and women receive different proportions of critical vs.\ supportive advice when posting about relationship problems?
    \item \textbf{RQ2}: Do these differences persist after controlling for confounding variables such as situation severity and poster fault?
    \item \textbf{RQ3}: Does the pattern vary by problem category?
\end{itemize}

\section{Related Work}

\subsection{Gender Bias in Online Communities}

Research has documented various forms of gender bias in online spaces. Women face higher rates of harassment on social media \citep{pew2017} and are underrepresented as contributors on platforms like Wikipedia \citep{hill2013wikipedia}. In professional contexts, studies have found that women receive different feedback than men---often less specific and more focused on personality rather than performance \citep{correll2016research}.

The advice-giving context presents a distinct dynamic. Unlike harassment or professional feedback, advice is ostensibly offered to help the recipient. Yet the framing of advice---whether it validates or challenges the recipient's perspective---may still be influenced by gender stereotypes about who deserves sympathy versus accountability.

\subsection{Advice-Giving Dynamics}

The literature on advice-giving distinguishes between supportive and challenging responses \citep{goldsmith2004communicating}. Supportive advice validates the recipient's feelings and perspective, while challenging advice questions their assumptions or behavior. Both can be appropriate depending on the situation, but systematic differences in who receives which type could indicate bias.

Research on therapeutic contexts suggests that men and women may receive different types of support. Men are sometimes perceived as needing ``tough love'' while women receive more nurturing responses \citep{addis2003men}. Whether these patterns extend to informal online advice-giving remains unexplored.

\subsection{LLM-Based Content Analysis}

Large language models have emerged as powerful tools for content analysis at scale \citep{ziems2024can}. LLMs can classify text along multiple dimensions simultaneously, enabling analysis of large corpora that would be infeasible with manual coding. However, LLM classification requires careful validation against human judgment to ensure reliability \citep{gilardi2023chatgpt}.

Recent work has demonstrated that LLMs can achieve human-level performance on various classification tasks, including sentiment analysis and topic categorization \citep{tornberg2023chatgpt}. We build on this literature by using LLM classification for advice analysis, with systematic validation of classifier accuracy.

\section{Data and Methods}

\subsection{Data Collection}

We collected data from Ask Metafilter (ask.metafilter.com), a question-and-answer community that has operated since 2003. Ask Metafilter is known for its active moderation and community norms that encourage thoughtful responses. We focused on posts tagged with ``relationships,'' which covers interpersonal advice requests.

We scraped all posts with the relationships tag from the past several years, collecting both the original posts and all associated comments. Our final dataset comprises:

\begin{itemize}
    \item \textbf{Posts}: 591 relationship advice posts with identifiable poster gender
    \item \textbf{Comments}: 7,091 total comments, of which 6,080 contained substantive advice
    \item \textbf{Gender distribution}: 1,716 comments on male-authored posts; 4,364 comments on female-authored posts
\end{itemize}

The gender imbalance in posts reflects the underlying community composition; Ask Metafilter has a predominantly female user base for relationship-related questions.

\subsection{Classification Framework}

For each post, we extracted:

\begin{enumerate}
    \item \textbf{Poster gender}: Identified from explicit mentions in the post text (e.g., ``I [30M]...'' or ``My husband and I [32F]...''). Posts without clear gender indicators were excluded.
    \item \textbf{Situation severity}: Low, medium, or high, based on the seriousness of the problem described.
    \item \textbf{OP fault}: None, some, substantial, or unclear, based on how much the poster appears to contribute to the problem.
    \item \textbf{Problem category}: The type of relationship issue (e.g., communication, trust, boundaries, compatibility).
\end{enumerate}

For each comment, we classified:

\begin{enumerate}
    \item \textbf{Is advice}: Boolean indicating whether the comment provides advice (as opposed to questions, jokes, or tangential discussion).
    \item \textbf{Advice direction}:
    \begin{itemize}
        \item \emph{Supportive of OP}: Validates the poster's perspective, sides with them
        \item \emph{Critical of OP}: Criticizes the poster's behavior or decisions
        \item \emph{Neutral}: Balanced or non-judgmental advice
        \item \emph{Mixed}: Contains both supportive and critical elements
    \end{itemize}
\end{enumerate}

\subsection{LLM Classification}

We used Claude Sonnet 4.5 (model ID: \texttt{claude-sonnet-4-5-20250929}) for automated classification. The model was prompted to analyze each comment in the context of the original post and return structured JSON with the classification fields.

The classification prompt was iteratively refined through pilot testing. We developed conservative criteria requiring explicit evidence for critical classifications. For example, ``critical of OP'' was defined as directly criticizing the poster's behavior, decisions, mindset, or perspective---not merely offering alternative viewpoints or practical suggestions.

\subsection{Validation}

To validate classification accuracy, we conducted human spot-checking using a custom web-based validation interface.

\subsubsection{Sampling Procedure}

We created a stratified random sample of 200 comments: 100 from posts by male authors and 100 from posts by female authors. Comments were interleaved and presented in random order to prevent any systematic ordering effects.

\subsubsection{Blind Validation Protocol}

The validation interface was designed to ensure independent human judgment. For each comment, the reviewer saw:

\begin{itemize}
    \item The original post (title and body text)
    \item The comment to be classified
    \item Four classification options: Supportive of OP, Critical of OP, Neutral, or Mixed
\end{itemize}

Critically, the reviewer did \textbf{not} see the LLM's classification. The LLM's judgment was stored but hidden during validation, and comparison occurred only after the human submitted their independent rating. This blind design ensures that human judgments were not anchored by the LLM's predictions.

The reviewer could see the original post text, which sometimes contained gender markers (e.g., ``My [30M] girlfriend...''). However, this does not compromise the validation, as the purpose was to assess whether the LLM correctly classified advice direction---not to measure human bias.

\subsubsection{Agreement Results}

For advice direction---our primary outcome measure---the LLM classifier achieved \textbf{96\% agreement} with human judgment (192 of 200 comments). Disagreements were primarily in edge cases where comments contained elements of both support and criticism.

\subsection{Statistical Methods}

We computed:

\begin{itemize}
    \item \textbf{Proportions}: Percentage of comments in each category by poster gender
    \item \textbf{Odds ratios}: Relative likelihood of receiving critical vs.\ supportive advice
    \item \textbf{Chi-square tests}: For independence between gender and advice type
    \item \textbf{Stratified analysis}: Repeating analyses within subgroups defined by severity, fault, and category
\end{itemize}

All statistical tests are two-tailed with $\alpha = 0.05$. Given the large sample size, we focus on effect sizes (odds ratios) in addition to p-values.

\section{Results}

\subsection{Dataset Characteristics}

Table~\ref{tab:characteristics} shows the distribution of posts by gender and key confound variables.

\begin{table}[h]
\centering
\caption{Post Characteristics by Poster Gender}
\label{tab:characteristics}
\begin{tabular}{lcccc}
\toprule
Variable & Male (n=199) & Female (n=392) & $\chi^2$ & $p$ \\
\midrule
\textbf{Severity} & & & 2.31 & 0.315 \\
\quad Low & 18.1\% & 21.4\% & & \\
\quad Medium & 52.3\% & 48.7\% & & \\
\quad High & 29.6\% & 29.9\% & & \\
\midrule
\textbf{OP Fault} & & & 3.87 & 0.276 \\
\quad None & 31.2\% & 35.7\% & & \\
\quad Some & 42.7\% & 38.5\% & & \\
\quad Substantial & 15.6\% & 17.1\% & & \\
\quad Unclear & 10.5\% & 8.7\% & & \\
\bottomrule
\end{tabular}
\end{table}

The distributions of severity and fault do not differ significantly by gender, suggesting that men and women post about situations of comparable difficulty.

\subsection{Primary Finding: Advice Direction}

Table~\ref{tab:direction} presents the main results on advice direction.

\begin{table}[h]
\centering
\caption{Advice Direction by Poster Gender}
\label{tab:direction}
\begin{tabular}{lccc}
\toprule
Advice Direction & Male (n=1,716) & Female (n=4,364) & Difference \\
\midrule
Critical of OP & 27.4\% & 8.3\% & +19.2 pp \\
Supportive of OP & 29.8\% & 42.1\% & $-$12.3 pp \\
Neutral & 31.2\% & 38.4\% & $-$7.2 pp \\
Mixed & 11.6\% & 11.2\% & +0.4 pp \\
\bottomrule
\end{tabular}
\end{table}

Men receive critical advice at significantly higher rates than women ($\chi^2 = 381.80$, $p < 0.0001$). The odds ratio is \textbf{4.19} (95\% CI: 3.58--4.90), meaning men are more than four times as likely to receive critical advice compared to women.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{chart_critical_by_gender.pdf}
\caption{Critical advice rates by poster gender. Men receive critical advice at 27.4\% compared to 8.3\% for women, representing a 4.19x difference in odds.}
\label{fig:critical_by_gender}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{chart_advice_distribution.pdf}
\caption{Distribution of all advice types by poster gender. The stacked bars show the proportion of critical, mixed, neutral, and supportive advice received by men and women.}
\label{fig:advice_distribution}
\end{figure}

\subsection{Analysis by Problem Category}

Table~\ref{tab:category} shows the critical advice rate by gender, stratified by problem category.

\begin{table}[h]
\centering
\caption{Critical Advice Rate by Gender and Problem Category}
\label{tab:category}
\begin{tabular}{lcccc}
\toprule
Category & Male & Female & Difference & $p$ \\
\midrule
Finances & 44.4\% & 8.6\% & +35.9 pp & 0.002 \\
Commitment & 33.0\% & 5.7\% & +27.3 pp & $<$0.0001 \\
Communication & 29.1\% & 7.9\% & +21.2 pp & $<$0.0001 \\
Boundaries & 29.7\% & 9.3\% & +20.4 pp & $<$0.0001 \\
Intimacy & 18.5\% & 5.6\% & +12.9 pp & $<$0.0001 \\
Lifestyle & 25.7\% & 14.3\% & +11.4 pp & 0.003 \\
Infidelity & 14.6\% & 16.4\% & $-$1.8 pp & 0.886 \\
\bottomrule
\end{tabular}
\end{table}

The gender disparity is significant across nearly all problem categories. The one exception is infidelity, where men and women receive similar rates of critical advice. This suggests that when cheating is involved, commenters may apply more uniform standards regardless of gender.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{chart_by_category.pdf}
\caption{Critical advice rates by problem category and poster gender. The gender gap is present across nearly all categories, with the largest disparities in finances and commitment issues.}
\label{fig:by_category}
\end{figure}

\subsection{Confound Analysis}

To test whether the observed differences might be explained by men posting about objectively worse situations, we conducted stratified analyses by situation severity and OP fault. In all strata, the gender disparity persists: men receive significantly more critical advice than women, even when comparing posters with similar severity levels and apparent fault.

\section{Discussion}

\subsection{Summary of Findings}

Our analysis reveals substantial gender disparities in online relationship advice. Men are more than four times more likely than women to receive critical advice, and this pattern persists after controlling for situation severity and poster fault. The disparity is consistent across most problem categories, with the notable exception of infidelity.

\subsection{Interpretation}

Several mechanisms could explain these findings:

\textbf{Commenter stereotypes}: Commenters may hold implicit beliefs that men need ``tough love'' while women need emotional support. Research on gender stereotypes in feedback contexts supports this interpretation \citep{correll2016research}.

\textbf{Differential standards}: Commenters may apply different standards of accountability to men and women. The same behavior might be interpreted as a mistake when described by a woman but as a character flaw when described by a man.

\textbf{Writing style differences}: Men and women may describe similar situations differently, in ways that elicit different responses. However, our confound analysis suggests this is unlikely to fully explain the observed disparities.

\textbf{Community composition}: Ask Metafilter's user base skews female. In-group favoritism could contribute to more sympathetic treatment of female posters.

\subsection{The Infidelity Exception}

The lack of gender disparity in infidelity-related posts is noteworthy. One interpretation is that infidelity represents a clear moral violation where commenters apply consistent standards. In ambiguous situations (communication problems, boundary issues), there may be more room for implicit biases to influence judgment.

\subsection{Implications}

\textbf{For help-seekers}: Men seeking relationship advice online should be aware that responses may be more critical than average. This awareness could help contextualize feedback.

\textbf{For communities}: Platform designers and moderators should consider whether their communities inadvertently create different experiences for different groups. Explicit guidelines about advice-giving norms might help reduce bias.

\textbf{For research}: Our LLM-based methodology demonstrates the feasibility of large-scale advice analysis. Future work could extend this approach to other platforms and domains.

\section{Limitations}

\textbf{Single platform}: Our data comes from Ask Metafilter, which has particular community norms and demographics. Results may not generalize to other advice forums.

\textbf{LLM classification}: While we validated our classifier against human judgment, automated classification introduces measurement error. Our focus on the high-reliability advice direction metric mitigates this concern.

\textbf{Selection effects}: We cannot observe who chooses \emph{not} to post. If men anticipate harsh responses and self-censor, our sample may underrepresent men who would receive the harshest advice.

\textbf{Correlation not causation}: We document a pattern but cannot identify its cause. Experimental methods would be needed to establish whether commenter bias, post content, or other factors drive the disparity.

\textbf{Binary gender}: Our analysis focuses on posts with explicitly stated binary gender. We cannot draw conclusions about non-binary individuals or situations where gender is not disclosed.

\section{Conclusion}

This study provides evidence of substantial gender disparities in online relationship advice. Men receive critical advice at more than four times the rate of women, and this pattern persists across different situation types and after controlling for apparent severity and fault. These findings suggest that gender shapes the advice-giving dynamic in online communities, with potential implications for help-seeking behavior and community design.

Future research should examine whether these patterns replicate across platforms, investigate the mechanisms underlying the disparity, and explore interventions that might promote more equitable advice-giving.

\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Addis and Mahalik(2003)]{addis2003men}
Addis, M.~E. and Mahalik, J.~R. (2003).
\newblock Men, masculinity, and the contexts of help seeking.
\newblock \emph{American Psychologist}, 58(1):5--14.

\bibitem[Anthropic(2025)]{anthropic2025}
Anthropic (2025).
\newblock Claude Sonnet 4.5 model card.

\bibitem[Correll and Simard(2016)]{correll2016research}
Correll, S.~J. and Simard, C. (2016).
\newblock Research: Vague feedback is holding women back.
\newblock \emph{Harvard Business Review}.

\bibitem[Duggan(2017)]{duggan2017}
Duggan, M. (2017).
\newblock Online harassment 2017.
\newblock Pew Research Center.

\bibitem[Ford et~al.(2016)]{ford2016paradise}
Ford, D., Smith, J., Guo, P.~J., and Parnin, C. (2016).
\newblock Paradise unplugged: Identifying barriers for female participation on Stack Overflow.
\newblock In \emph{Proceedings of the 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering}, pages 846--857.

\bibitem[Gilardi et~al.(2023)]{gilardi2023chatgpt}
Gilardi, F., Alizadeh, M., and Kubli, M. (2023).
\newblock ChatGPT outperforms crowd-workers for text-annotation tasks.
\newblock \emph{arXiv preprint arXiv:2303.15056}.

\bibitem[Goldsmith(2004)]{goldsmith2004communicating}
Goldsmith, D.~J. (2004).
\newblock \emph{Communicating Social Support}.
\newblock Cambridge University Press.

\bibitem[Hill and Shaw(2013)]{hill2013wikipedia}
Hill, B.~M. and Shaw, A. (2013).
\newblock The Wikipedia gender gap revisited: Characterizing survey response bias with propensity score estimation.
\newblock \emph{PloS One}, 8(6):e65782.

\bibitem[Lam et~al.(2011)]{lam2011wp}
Lam, S. T.~K., Uduwage, A., Dong, Z., Sen, S., Musicant, D.~R., Terveen, L., and Riedl, J. (2011).
\newblock WP:Clubhouse? An exploration of Wikipedia's gender imbalance.
\newblock In \emph{Proceedings of the 7th International Symposium on Wikis and Open Collaboration}, pages 1--10.

\bibitem[Pew Research Center(2017)]{pew2017}
Pew Research Center (2017).
\newblock Online harassment 2017.

\bibitem[T{\"o}rnberg(2023)]{tornberg2023chatgpt}
T{\"o}rnberg, P. (2023).
\newblock ChatGPT-4 outperforms experts and crowd workers in annotating political Twitter messages with zero-shot learning.
\newblock \emph{arXiv preprint arXiv:2304.06588}.

\bibitem[Ziems et~al.(2024)]{ziems2024can}
Ziems, C., Held, W., Shaber, O., Lu, J., Levy, M., Lahav, G., et~al. (2024).
\newblock Can large language models transform computational social science?
\newblock \emph{Computational Linguistics}, 50(1):237--291.

\end{thebibliography}

\end{document}
