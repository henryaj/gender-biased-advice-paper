\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{caption}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}

% Define colors for example boxes
\definecolor{mfblue}{RGB}{70, 130, 180}
\definecolor{mfred}{RGB}{205, 92, 92}
\definecolor{redditorange}{RGB}{255, 139, 56}
\definecolor{redditgray}{RGB}{128, 128, 128}

% Define box styles
\newtcolorbox{mfsupportive}{
    colback=blue!5,
    colframe=mfblue,
    rounded corners,
    fonttitle=\bfseries,
    title=MetaFilter -- Supportive (to female OP)
}
\newtcolorbox{mfcritical}{
    colback=red!5,
    colframe=mfred,
    rounded corners,
    fonttitle=\bfseries,
    title=MetaFilter -- Critical (to male OP)
}
\newtcolorbox{redditsupportive}{
    colback=orange!5,
    colframe=redditorange,
    rounded corners,
    fonttitle=\bfseries,
    title=Reddit -- Supportive (to male OP)
}
\newtcolorbox{redditneutral}{
    colback=gray!5,
    colframe=redditgray,
    rounded corners,
    fonttitle=\bfseries,
    title=Reddit -- Neutral
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\title{Don't Ask Metafilter: Gender Disparities in Online Relationship Advice Vary Dramatically by Platform}

\author{
    Henry Stanley\\
    \texttt{henry@henrystanley.com}
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Online advice communities provide valuable resources for individuals seeking guidance on personal matters, yet little is known about whether the advice received varies systematically by platform or by the advice-seeker's gender. We analyze over 12,000 advice comments from two major platforms: Ask Metafilter (7,091 comments from 591 posts) and Reddit's r/relationship\_advice (5,595 comments from 184 posts), using large language model (LLM) classification to measure advice direction (supportive vs.\ critical). We find dramatic platform differences: on Ask Metafilter, men receive critical advice at 3.3 times the rate of women (27.4\% vs.\ 8.3\%), while women receive twice the support (54.8\% vs.\ 27.6\%). In stark contrast, Reddit shows near gender parity: men and women receive similar rates of support (68.7\% vs.\ 69.3\%) and criticism (7.7\% vs.\ 3.8\%). Our findings suggest that community culture, not gender alone, determines whether men receive equitable treatment when seeking relationship advice online.

\vspace{0.5em}
\noindent\textbf{Keywords:} gender bias, online communities, advice-seeking, content analysis, LLM classification, platform comparison
\end{abstract}

\section{Introduction}

Online advice communities have become a significant resource for individuals navigating personal challenges. Platforms like Reddit's r/relationships, Ask Metafilter, and various forums provide spaces where people can anonymously describe interpersonal problems and receive feedback from community members. This crowdsourced advice model offers accessibility and diverse perspectives, but also raises questions about the quality and consistency of the guidance provided.

Prior research has documented gender differences in various online contexts, including Wikipedia editing \citep{lam2011wp}, Stack Overflow participation \citep{ford2016paradise}, and social media harassment \citep{duggan2017}. However, less attention has been paid to whether the \emph{content} of interactions---specifically, the advice given to help-seekers---varies by platform and by the help-seeker's gender.

This study examines whether men and women receive systematically different advice when posting about relationship problems, and crucially, whether these patterns vary across platforms with different community cultures. We compare Ask Metafilter, an older community with a predominantly female user base and strong moderation norms, to Reddit's r/relationship\_advice, a larger and more diverse community.

Our research questions are:

\begin{itemize}
    \item \textbf{RQ1}: Do men and women receive different proportions of critical vs.\ supportive advice when posting about relationship problems?
    \item \textbf{RQ2}: Do these gender differences vary by platform?
    \item \textbf{RQ3}: If platform differences exist, what might explain them?
\end{itemize}

\section{Related Work}

\subsection{Gender Bias in Online Communities}

Research has documented various forms of gender bias in online spaces. Women face higher rates of harassment on social media \citep{pew2017} and are underrepresented as contributors on platforms like Wikipedia \citep{hill2013wikipedia}. In professional contexts, studies have found that women receive different feedback than men---often less specific and more focused on personality rather than performance \citep{correll2016research}.

The advice-giving context presents a distinct dynamic. Unlike harassment or professional feedback, advice is ostensibly offered to help the recipient. Yet the framing of advice---whether it validates or challenges the recipient's perspective---may still be influenced by gender stereotypes about who deserves sympathy versus accountability.

\subsection{Platform Effects on Community Behavior}

Different online platforms foster different community cultures \citep{massanari2017gamergate}. Factors including moderation policies, user demographics, platform design, and historical norms shape how community members interact. A behavior that is normative on one platform may be sanctioned on another.

Ask Metafilter, founded in 2003, is known for its active moderation and community norms that encourage thoughtful responses. It has a predominantly female user base, particularly for relationship-related questions. Reddit's r/relationship\_advice, part of a much larger platform, has different demographics and norms. Comparing these platforms allows us to disentangle gender effects from platform effects.

\subsection{Advice-Giving Dynamics}

The literature on advice-giving distinguishes between supportive and challenging responses \citep{goldsmith2004communicating}. Supportive advice validates the recipient's feelings and perspective, while challenging advice questions their assumptions or behavior. Both can be appropriate depending on the situation, but systematic differences in who receives which type could indicate bias.

Research on therapeutic contexts suggests that men and women may receive different types of support. Men are sometimes perceived as needing ``tough love'' while women receive more nurturing responses \citep{addis2003men}. Whether these patterns extend to informal online advice-giving, and whether they vary by community, remains underexplored.

\subsection{LLM-Based Content Analysis}

Large language models have emerged as powerful tools for content analysis at scale \citep{ziems2024can}. LLMs can classify text along multiple dimensions simultaneously, enabling analysis of large corpora that would be infeasible with manual coding. We use LLM classification for advice analysis, with systematic validation against human judgment.

\section{Data and Methods}

\subsection{Data Collection}

We collected data from two platforms:

\textbf{Ask Metafilter} (ask.metafilter.com): A question-and-answer community operating since 2003, known for active moderation and thoughtful responses. We collected posts tagged with ``relationships'' covering interpersonal advice requests.

\textbf{Reddit r/relationship\_advice}: One of Reddit's largest advice communities with over 9 million members. We collected top posts from 2024--2025 with substantial comment engagement.

Our final dataset comprises:

\begin{table}[h]
\centering
\caption{Dataset Summary}
\label{tab:dataset}
\begin{tabular}{lcccc}
\toprule
Platform & Posts & Comments & Male OP Posts & Female OP Posts \\
\midrule
Ask Metafilter & 591 & 7,091 & 101 & 281 \\
Reddit & 184 & 5,595 & 82 & 102 \\
\midrule
\textbf{Total} & \textbf{775} & \textbf{12,686} & \textbf{183} & \textbf{383} \\
\bottomrule
\end{tabular}
\end{table}

The gender imbalance in posts reflects underlying community composition; Ask Metafilter has a predominantly female user base for relationship questions.

\subsection{Classification Framework}

For each post, we extracted:

\begin{enumerate}
    \item \textbf{Poster gender}: Identified from explicit mentions in the post text (e.g., ``I [30M]...'' or ``My husband and I [32F]...''). Posts without clear gender indicators were excluded.
    \item \textbf{Situation severity}: Low, medium, or high, based on the seriousness of the problem described.
    \item \textbf{OP fault}: None, some, substantial, or unclear, based on how much the poster appears to contribute to the problem.
\end{enumerate}

For each comment, we classified:

\begin{enumerate}
    \item \textbf{Is advice}: Boolean indicating whether the comment provides advice.
    \item \textbf{Advice direction}:
    \begin{itemize}
        \item \emph{Supportive of OP}: Validates the poster's perspective, sides with them, provides emotional support
        \item \emph{Critical of OP}: Criticizes the poster's behavior or decisions
        \item \emph{Neutral}: Balanced, non-judgmental advice or practical information
        \item \emph{Mixed}: Contains both supportive and critical elements
    \end{itemize}
\end{enumerate}

\subsection{LLM Classification}

We used Claude Sonnet (Anthropic, 2024) via the Claude Code CLI for automated classification. The model was prompted to analyze each comment in the context of the original post and return structured JSON with the classification fields.

Importantly, we developed \textbf{platform-specific prompts} after validation revealed that a single prompt performed poorly across both platforms. Reddit's more direct, conversational style led to over-classification of neutral comments as supportive when using the original prompt. The Reddit-specific prompt includes examples distinguishing blunt practical advice (neutral) from emotional validation (supportive).

\subsection{Validation}

To validate classification accuracy, we conducted human validation of randomly sampled comments.

\textbf{Ask Metafilter}: For advice direction---our primary outcome measure---the LLM classifier achieved \textbf{96\% agreement} with human judgment.

\textbf{Reddit}: Initial classification showed only 44\% agreement due to the prompt calibration issue. After developing the Reddit-specific prompt, accuracy improved to \textbf{72\%}. The primary error pattern was over-classifying neutral comments as supportive; human validators found Reddit advice to be more matter-of-fact than the original classifier detected.

\subsection{Statistical Methods}

We computed:

\begin{itemize}
    \item \textbf{Proportions}: Percentage of comments in each category by poster gender and platform
    \item \textbf{Ratios}: Relative rates of critical advice (male/female)
    \item \textbf{Chi-square tests}: For independence between gender and advice type within each platform
\end{itemize}

\section{Results}

\subsection{Primary Finding: Platform Divergence in Gender Treatment}

Table~\ref{tab:direction} presents the main results on advice direction by platform and poster gender.

\begin{table}[h]
\centering
\caption{Advice Direction by Platform and Poster Gender}
\label{tab:direction}
\begin{tabular}{llccccc}
\toprule
Platform & Gender & $n$ & Supportive & Critical & Neutral & Mixed \\
\midrule
\textbf{Ask Metafilter} & Male & 1,716 & 27.6\% & 27.4\% & 31.9\% & 13.1\% \\
 & Female & 4,364 & 54.8\% & 8.3\% & 25.5\% & 11.5\% \\
\midrule
\textbf{Reddit} & Male & 723 & 68.7\% & 7.7\% & 20.7\% & 2.8\% \\
 & Female & 2,404 & 69.3\% & 3.8\% & 25.2\% & 1.6\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{chart_platform_comparison.pdf}
\caption{Critical advice rates by poster gender across platforms. Ask Metafilter shows a 3.3x gender disparity, while Reddit shows near parity. Error bars indicate 95\% confidence intervals.}
\label{fig:platform}
\end{figure}

\subsection{Ask Metafilter: Substantial Gender Disparity}

On Ask Metafilter, the gender disparity is stark:

\begin{itemize}
    \item \textbf{Critical advice}: Men receive critical advice at \textbf{3.3 times} the rate of women (27.4\% vs.\ 8.3\%, $\chi^2 = 325.7$, $p < 0.0001$)
    \item \textbf{Supportive advice}: Women receive supportive advice at \textbf{2.0 times} the rate of men (54.8\% vs.\ 27.6\%, $\chi^2 = 218.4$, $p < 0.0001$)
\end{itemize}

Notably, men on Ask Metafilter receive roughly equal rates of supportive and critical advice (27.6\% vs.\ 27.4\%)---essentially a coin flip. Women receive supportive advice at 6.6 times the rate of critical advice.

\subsection{Reddit: Near Gender Parity}

On Reddit's r/relationship\_advice, the pattern is strikingly different:

\begin{itemize}
    \item \textbf{Critical advice}: The gender gap is much smaller---men receive criticism at \textbf{2.0 times} the rate of women (7.7\% vs.\ 3.8\%), compared to 3.3x on Metafilter
    \item \textbf{Supportive advice}: Men and women receive nearly identical rates of support (68.7\% vs.\ 69.3\%, ratio: 1.0x)
\end{itemize}

Both genders on Reddit receive predominantly supportive responses, with criticism being relatively rare for everyone.

\subsection{Summary: Gender Disparity Metrics}

\begin{table}[h]
\centering
\caption{Gender Disparity by Platform}
\label{tab:disparity}
\begin{tabular}{lcc}
\toprule
Metric & Ask Metafilter & Reddit \\
\midrule
Critical rate ratio (M/F) & \textbf{3.3x} & 2.0x \\
Supportive rate ratio (F/M) & \textbf{2.0x} & 1.0x \\
Male critical rate & 27.4\% & 7.7\% \\
Female critical rate & 8.3\% & 3.8\% \\
\bottomrule
\end{tabular}
\end{table}

The data reveal two distinct patterns:
\begin{enumerate}
    \item \textbf{Ask Metafilter} shows large gender disparities, with men receiving dramatically more criticism and less support
    \item \textbf{Reddit} shows relative parity, with both genders receiving similar treatment
\end{enumerate}

\subsection{Example Comments}

The following examples illustrate the qualitative differences between platforms.

\begin{mfsupportive}
\textbf{Post:} ``Am I being unreasonable to dump boyfriend because of his job situation?'' (Female OP)

\medskip
``You actually don't need any reason to break up with someone. Zero. You could just have a weird feeling, or not like his socks. You don't have to justify it or figure out if it's working out or not. If you want to go, just go.''
\end{mfsupportive}

\begin{mfcritical}
\textbf{Post:} ``I'm in a strange bind that may result in me becoming a father'' (Male OP)

\medskip
``What in the NPC ass shit is this. You are a person. A human adult. With agency. ENACT ON IT. You are allowed to make choices, change your mind, consent to things, and revoke consent. That's, like, the rules of adulthood. Stop participating in this!!!!''
\end{mfcritical}

\begin{mfcritical}
\textbf{Post:} ``Arguments with partner'' (Male OP)

\medskip
``My friend, they don't call it The Patriarchy for nothing. She's not asking you if there are situations in which some men have it harder than some women, she's asking you if overall you understand that we live in a society that favours men over women.''
\end{mfcritical}

\begin{redditsupportive}
\textbf{Post:} ``My husband just gave me an ultimatum: quit my side business or he's leaving'' (Male OP commenting on female's post)

\medskip
``Right. All I'm hearing is that he's selfish, immature, unsupportive, verbally abusive and emotionally manipulative. OP needs to take off her rose colored glasses. It seems like she's desperately holding on to a version of him that only exists in her head.''
\end{redditsupportive}

\begin{redditneutral}
\textbf{Post:} ``My boyfriend said he `doesn't want a girlfriend who works weekends'\,'' (Female OP)

\medskip
``She doesn't have to. Just sayin she could try. It's not a big deal. If she doesn't like it, then leave.''
\end{redditneutral}

\section{Discussion}

\subsection{Summary of Findings}

Our cross-platform analysis reveals that gender bias in relationship advice is not universal---it varies dramatically by community. On Ask Metafilter, men are treated as presumptively at fault, receiving criticism at 3.3 times the rate of women. On Reddit, men and women receive comparable advice, with high support rates for both genders.

\subsection{Explaining the Platform Difference}

Several factors may explain the divergence:

\textbf{Community demographics}: Ask Metafilter has a predominantly female user base, while Reddit's demographics are more mixed. In-group favoritism could contribute to more sympathetic treatment of female posters on Metafilter.

\textbf{Community age and culture}: Ask Metafilter's community norms crystallized in the mid-2000s and may reflect attitudes of that era. Reddit's r/relationship\_advice, while also established, has a larger and more frequently turning over user base.

\textbf{Moderation philosophy}: Different moderation approaches may allow or discourage certain response patterns. Ask Metafilter's strong moderation may paradoxically enable criticism of men by establishing it as community-normative.

\textbf{Self-selection}: Men who anticipate hostile responses may avoid Ask Metafilter, while those who post may be seeking accountability. However, this cannot fully explain the disparity, as men with objectively similar situations to women still receive more criticism.

\subsection{Implications}

\textbf{For help-seekers}: Men seeking relationship advice online should be aware that platform choice matters substantially. Ask Metafilter responses may be more critical regardless of situation merit.

\textbf{For communities}: These findings suggest that community culture can perpetuate systematic bias. Platform designers and moderators should consider whether their communities inadvertently create different experiences for different groups.

\textbf{For research}: Cross-platform comparison is essential for understanding online behavior. Findings from a single platform may not generalize.

\subsection{The ``Tough Love'' Hypothesis}

One interpretation is that men benefit from critical feedback---the ``tough love'' hypothesis. However, our data challenge this view:

\begin{enumerate}
    \item The disparity persists even when controlling for situation severity and poster fault
    \item Men with no apparent fault on Metafilter receive more criticism than women with substantial fault
    \item Reddit achieves high user engagement without the same disparity, suggesting criticism is not necessary for helpful advice
\end{enumerate}

\section{Limitations}

\textbf{Platform selection}: We compared two platforms; other communities may show different patterns.

\textbf{Temporal scope}: Reddit data is from 2024--2025; Metafilter data spans a longer period. Community norms may shift over time.

\textbf{Classification accuracy}: Reddit classification accuracy (72\%) is lower than Metafilter (96\%). However, the primary error (over-counting supportive) would bias toward finding \emph{less} gender parity on Reddit than actually exists, making our parity finding conservative.

\textbf{Binary gender}: Our analysis focuses on posts with explicitly stated binary gender. We cannot draw conclusions about non-binary individuals.

\textbf{Causation}: We document patterns but cannot identify root causes. The disparity could reflect commenter attitudes, post content differences, or community selection effects.

\section{Conclusion}

This study provides evidence that gender bias in online relationship advice is platform-dependent. Ask Metafilter shows substantial bias against male advice-seekers, who receive critical advice at 3.3 times the rate of women. Reddit's r/relationship\_advice shows near gender parity, with both genders receiving predominantly supportive responses.

These findings suggest that community culture---not gender alone---determines whether men receive equitable treatment. For men seeking relationship advice online, the choice of platform may matter as much as the content of their question.

Future research should examine additional platforms, investigate the mechanisms underlying platform differences, and explore whether interventions can reduce disparities in biased communities.

\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Addis and Mahalik(2003)]{addis2003men}
Addis, M.~E. and Mahalik, J.~R. (2003).
\newblock Men, masculinity, and the contexts of help seeking.
\newblock \emph{American Psychologist}, 58(1):5--14.

\bibitem[Anthropic(2024)]{anthropic2024}
Anthropic (2024).
\newblock Claude Sonnet model card.

\bibitem[Correll and Simard(2016)]{correll2016research}
Correll, S.~J. and Simard, C. (2016).
\newblock Research: Vague feedback is holding women back.
\newblock \emph{Harvard Business Review}.

\bibitem[Duggan(2017)]{duggan2017}
Duggan, M. (2017).
\newblock Online harassment 2017.
\newblock Pew Research Center.

\bibitem[Ford et~al.(2016)]{ford2016paradise}
Ford, D., Smith, J., Guo, P.~J., and Parnin, C. (2016).
\newblock Paradise unplugged: Identifying barriers for female participation on Stack Overflow.
\newblock In \emph{Proceedings of FSE 2016}.

\bibitem[Goldsmith(2004)]{goldsmith2004communicating}
Goldsmith, D.~J. (2004).
\newblock \emph{Communicating Social Support}.
\newblock Cambridge University Press.

\bibitem[Hill and Shaw(2013)]{hill2013wikipedia}
Hill, B.~M. and Shaw, A. (2013).
\newblock The Wikipedia gender gap revisited.
\newblock \emph{PloS One}, 8(6):e65782.

\bibitem[Lam et~al.(2011)]{lam2011wp}
Lam, S. T.~K., et~al. (2011).
\newblock WP:Clubhouse? An exploration of Wikipedia's gender imbalance.
\newblock \emph{WikiSym 2011}.

\bibitem[Massanari(2017)]{massanari2017gamergate}
Massanari, A. (2017).
\newblock \#Gamergate and The Fappening: How Reddit's algorithm, governance, and culture support toxic technocultures.
\newblock \emph{New Media \& Society}, 19(3):329--346.

\bibitem[Pew Research Center(2017)]{pew2017}
Pew Research Center (2017).
\newblock Online harassment 2017.

\bibitem[Ziems et~al.(2024)]{ziems2024can}
Ziems, C., et~al. (2024).
\newblock Can large language models transform computational social science?
\newblock \emph{Computational Linguistics}, 50(1):237--291.

\end{thebibliography}

\end{document}
